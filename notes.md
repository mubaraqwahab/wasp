# Notes

Compilation comprises three main stages: parsing, transformation, and generation. An intermediate representation of the source code is created through parsing, then transformations are applied to the representation before a string of code in a target language is generated.

- [Lexing](#lexing)
- [Parsing](#parsing)
- [Semantics](#semantics)
- [Code Generation](#code-generation)
  - [Visitor Pattern](#visitor-pattern)

## Lexing

Parsing is of two phases; the first is lexical analysis, or _lexing_. A lexical analyzer is also known as a _lexer_. A lexer reads the source code and turns it into a stream of _tokens_. Tokens are categories of _lexemes_ (that is, words or units) in a language. For example, consider the JavaScript expression `alert('Hi');`. The lexemes in it are `alert`, `(`, `'Hi'`, `)` and `;`. `alert` might correspond to the identifier token, `(` the open parenthesis token, `'Hi'` the string literal token, and so on.

The following is a basic, informal procedure for lexing:

1. Iterate over the source code character by character.
2. Identify the token associated with each lexeme.
3. Add the identified tokens to an array of tokens.

There are some important ways the procedure above could be modified. It is often useful to store some token metadata such as the token's location in the source code, etc. It might also not be wise to store all tokens in an array &ndash; consider how large the array would grow when parsing a large file. A third thing is that whitespace tokens (spaces, tabs and newlines) need not be stored, they should only be identified. Finally, characters that do not fit into any token category should be treated as (lexical) syntax errors.

## Parsing

The second phase of parsing is syntactic analysis (or syntax analysis). It may simply be called _parsing_. This phase imposes an hierarchical structure on the tokens generated by the lexer. The structure, known as an abstract syntax tree (AST), serves as an intermediate representation of the source code, and it helps in validating the syntax of the code, among other uses.

> **Tips:**
> * [AST Explorer](https://astexplorer.net/) is one tool for inspecting ASTs.
> * There are AST specifications for languages relating to the web [@syntax-tree](https://github.com/syntax-tree). There are other specs as well, like [ESTree](https://github.com/estree/estree) for JavaScript.

Here's a simple procedure for building an AST:

1. Iterate over the array of tokens.
2. Add each number, string, etc. to the current level of the tree.
3. Collect the arguments of each _call expression_ (i.e. function call) and then recurse down into the function body.

Note that the lexing and parsing phases of compilation are _front-end_ phases because they deal with the source code.

## Semantics

It is important when designing a programming language to specify what each syntactic structure inherently "means". This is especially true for operators. These operators, and other built-in functions, objects, etc., that make up the language and its _standard library_ can be implemented in the target language of the compiler. (Higher-level functionality may be implemented using the language itself, though.)

## Code Generation

The _back-end_ phases of compilation are mostly concerned with optimizing the representation and generating code in the target language. Think of the latter as the "reverse" of parsing &ndash; transforming an AST into code.

There are many options for a target language. It could be a very low-level language like assembly, or some other intermediate representation for which some code generator already exists (like LLVM), or even another high-level language. Compiling to a similarly high-level language is called _transpiling_, and this is what many web build tools do &ndash; transpiling a language like TypeScript (or a language extension like JSX) to JavaScript.

### Visitor Pattern

Do a depth-first search of the AST and perform a certain action depending on the type of node visited.